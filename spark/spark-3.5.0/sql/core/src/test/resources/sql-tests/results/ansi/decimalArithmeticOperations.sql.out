-- Automatically generated by SQLQueryTestSuite
-- !query
create table decimals_test(id int, a decimal(38,18), b decimal(38,18)) using parquet
-- !query schema
struct<>
-- !query output



-- !query
insert into decimals_test values(1, 100.0, 999.0), (2, 12345.123, 12345.123),
  (3, 0.1234567891011, 1234.1), (4, 123456789123456789.0, 1.123456789123456789)
-- !query schema
struct<>
-- !query output



-- !query
select id, a*10, b/10 from decimals_test order by id
-- !query schema
struct<id:int,(a * 10):decimal(38,15),(b / 10):decimal(38,18)>
-- !query output
1	1000.000000000000000	99.900000000000000000
2	123451.230000000000000	1234.512300000000000000
3	1.234567891011000	123.410000000000000000
4	1234567891234567890.000000000000000	0.112345678912345679


-- !query
select 10.3 * 3.0
-- !query schema
struct<(10.3 * 3.0):decimal(6,2)>
-- !query output
30.90


-- !query
select 10.3000 * 3.0
-- !query schema
struct<(10.3000 * 3.0):decimal(9,5)>
-- !query output
30.90000


-- !query
select 10.30000 * 30.0
-- !query schema
struct<(10.30000 * 30.0):decimal(11,6)>
-- !query output
309.000000


-- !query
select 10.300000000000000000 * 3.000000000000000000
-- !query schema
struct<(10.300000000000000000 * 3.000000000000000000):decimal(38,34)>
-- !query output
30.9000000000000000000000000000000000


-- !query
select 10.300000000000000000 * 3.0000000000000000000
-- !query schema
struct<(10.300000000000000000 * 3.0000000000000000000):decimal(38,34)>
-- !query output
30.9000000000000000000000000000000000


-- !query
select (5e36BD + 0.1) + 5e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "1",
    "value" : "10000000000000000000000000000000000000.1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "(5e36BD + 0.1) + 5e36BD"
  } ]
}


-- !query
select (-4e36BD - 0.1) - 7e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "1",
    "value" : "-11000000000000000000000000000000000000.1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "(-4e36BD - 0.1) - 7e36BD"
  } ]
}


-- !query
select 12345678901234567890.0 * 12345678901234567890.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "2",
    "value" : "152415787532388367501905199875019052100"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "12345678901234567890.0 * 12345678901234567890.0"
  } ]
}


-- !query
select 1e35BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "1000000000000000000000000000000000000.00000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "1e35BD / 0.1"
  } ]
}


-- !query
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query schema
struct<(123456789123456789.1234567890 * 1.123456789123456789):decimal(38,18)>
-- !query output
138698367904130467.654320988515622621


-- !query
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query schema
struct<(123456789123456789.1234567890 * 1.123456789123456789):decimal(38,18)>
-- !query output
138698367904130467.654320988515622621


-- !query
select 12345678912345.123456789123 / 0.000000012345678
-- !query schema
struct<(12345678912345.123456789123 / 1.2345678E-8):decimal(38,9)>
-- !query output
1000000073899961059796.725866332


-- !query
select 1.0123456789012345678901234567890123456e36BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "10123456789012345678901234567890123456.00000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e36BD / 0.1"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e35BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "101234567890123456789012345678901234.56000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e35BD / 1.0"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e34BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "10123456789012345678901234567890123.45600000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e34BD / 1.0"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e33BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "1012345678901234567890123456789012.34560000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e33BD / 1.0"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e32BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "101234567890123456789012345678901.23456000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e32BD / 1.0"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e31BD / 1.0
-- !query schema
struct<(10123456789012345678901234567890.123456 / 1.0):decimal(38,6)>
-- !query output
10123456789012345678901234567890.123456


-- !query
select 1.0123456789012345678901234567890123456e31BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "101234567890123456789012345678901.23456000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e31BD / 0.1"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e31BD / 10.0
-- !query schema
struct<(10123456789012345678901234567890.123456 / 10.0):decimal(38,6)>
-- !query output
1012345678901234567890123456789.012346


-- !query
drop table decimals_test
-- !query schema
struct<>
-- !query output

